import os
import ast
from dotenv import load_dotenv
load_dotenv(dotenv_path="dags/.env")

import ollama
import logging
from qdrant_client import QdrantClient, models


class Retrieval:
    def __init__(self, embed_model: str = "imac/zpoint_large_embedding_zh"):
        """
        Initialize the Retrieval class.
        
        Args:
            **kwargs: Additional arguments.
        """
        try:
            self.embed_model = embed_model
            self.qdrant_client = QdrantClient(url=os.getenv("QDRANT_URL", "http://10.20.1.95:6333"))
        except Exception as e:
            logging.error(f"Error initializing Retrieval class: {e}")
            raise e
    
    @staticmethod
    def get_user_question(ti: object) -> str:
        """
        Get user question from XCom.
        
        Returns:
            user_question (str): The user's question.
        """
        try:
            user_question = ti.xcom_pull(task_ids='random_question_task', key='return_value')
            return user_question
        except Exception as e:
            logging.error(f"Error retrieving user question: {e}")
            return "What is the current number of electors currently in a Scottish Parliament constituency?"
    
    def ollama_embedding(self, prompt: str) -> list:
        """
        Generate embedding using ollama.
        
        Args:
            prompt (str): Text prompt to generate embedding.
        
        Returns:
            query_vector (list): Embedding vector generated by ollama.
        """
        try:
            return ollama.embeddings(
                model=self.embed_model,
                prompt=prompt,
                options={"device": "cpu"},
                keep_alive="0s"
            )["embedding"]  
        except Exception as e:
            logging.error(f"Error generating embedding: {e}")
            raise e  
        
    def similarity_search(self, collection_name: str, prompt: str, limit: int = 10) -> list:
        """
        Perform similarity search in Qdrant.
        
        Args:
            collection_name (str): Name of the Qdrant collection.
            prompt (str): Text prompt to generate embedding.
            limit (int): Number of results to return. Defaults to 10.
        
        Returns:
            result (list): List of search results.
        """
        try:
            query_vector = self.ollama_embedding(
                prompt=prompt
            )
            result = self.qdrant_client.search(
                collection_name=collection_name,
                query_vector=query_vector,
                limit=limit,
                score_threshold=0
            )
            return result
        except Exception as e:
            logging.error(f"Error during similarity search: {e}")
            raise e

    def keyword_search(self, collection_name: str, prompt: str, keywords: list, limit: int = 10) -> list:
        """
        Perform keyword search in Qdrant.
        
        Args:
            collection_name (str): Name of the Qdrant collection.
            prompt (str): Text prompt to generate embedding.
            keywords (list): List of keywords to search for.
            limit (int): Number of results to return. Defaults to 10.
        
        Returns:
            result (list): List of search results.
        """
        try:
            condition = []
            query_vector = self.ollama_embedding(
                prompt=prompt
            )
            for keyword in keywords:
                condition.append(
                    models.FieldCondition(
                        key="document",
                        match=models.MatchText(text=keyword),
                    )
                )
            result = self.qdrant_client.search(
                collection_name=collection_name,
                query_vector=query_vector,
                limit=limit,
                score_threshold=0,
                query_filter=models.Filter(
                    must=condition
                ),
            )
            return result
        except Exception as e:
            logging.error(f"Error during keyword search: {e}")
            raise e
        
    def retrieval(self, document_types: str = "squad", types: str = "similarity", **kwargs) -> list:
        """
        Retrieve relevant documents from Qdrant based on the user question.
        
        Args:
            document_types (str): The type of documents to retrieve. Defaults to "squad".
            types (str): The type of retrieval. Defaults to "similarity".
            **kwargs: Additional arguments.
            
        Returns:
            search_result (list): A list of retrieved documents.
        """
        try:
            ti = kwargs['ti']
            user_question = self.get_user_question(ti)
            logging.info(f"Retrieving information for question: {user_question}")
            search_result = []
            
            if types == "similarity":
                logging.info(f"Using similarity search")
                result = self.similarity_search(
                    collection_name=f"""{document_types}_{self.embed_model.split('/')[-1]}""",
                    prompt=user_question,
                    limit=10
                )
            elif types == "keyword":
                logging.info(f"Using keyword search")
                keyword_list = ti.xcom_pull(task_ids='keyword_extract_task', key='return_value')
                keyword_list = ast.literal_eval(f'[{keyword_list}]')
                logging.info(f"Keyword list: {keyword_list}")
                
                result = self.keyword_search(
                    collection_name=f"""{document_types}_{self.embed_model.split('/')[-1]}""",
                    prompt=user_question,
                    keywords=keyword_list,
                    limit=10
                )
            
            for index in range(len(result)):
                search_result.append(f"""{result[index].payload["document"]}""")
            
            return search_result
        except Exception as e:
            logging.error(f"Error during retrieval: {e}")
            raise e
                
    
# def retrieval(embed_model: str = "imac/zpoint_large_embedding_zh", types: str = "similarity", **kwargs) -> list:
#     """Retrieve relevant documents from Qdrant based on the user question.
    
#     Args:
#         # user_question (str): The user's question.
#         model (str): The model to be used for embeddings. Defaults to "gemma2:9b".
#         type (str): The type of retrieval. Defaults to "similarity".
#         **kwargs: Additional arguments.
        
#     Returns:
#         search_result (list): A list of retrieved documents.
#     """    
    
#     qdrant_client = QdrantClient(url=os.getenv("QDRANT_URL", "http://10.20.1.95:6333"))
#     content = ""
#     search_result = []
#     ti = kwargs['ti']
#     user_question = ti.xcom_pull(task_ids='random_question_task', key='return_value')
#     logging.info(f"Retrieving information for question: {user_question}")
    
#     if types == "similarity":
#         logging.info(f"Using similarity search")
#         result = qdrant_client.search(
#             collection_name=f"""squad_zpoint_large_embedding_zh""",
#             query_vector=ollama.embeddings(
#                 model=embed_model, 
#                 prompt=user_question,
#                 options={"device": "cpu"},
#                 keep_alive="0s"
#             )["embedding"],
#             limit=10,
#             score_threshold=0
#         )
        
#     elif types == "keyword":
#         logging.info(f"Using keyword search")
#         condition = []
#         keyword_list = ti.xcom_pull(task_ids='keyword_extract_task', key='return_value')
#         # keyword_list = ti.xcom_pull(task_ids='keyword_extract_task', key='keyword')
#         logging.info(f"Keyword list: {keyword_list}")
        
#         for keyword in keyword_list:
#             logging.info(f"Keyword: {keyword}")
#             condition.append(
#                 models.FieldCondition(
#                     key="document",
#                     match=models.MatchText(text=keyword),
#                 )
#             )
        
#         result = qdrant_client.search(
#             collection_name=f"""squad_zpoint_large_embedding_zh""",
#             query_vector=ollama.embeddings(
#                 model=embed_model, 
#                 prompt=user_question,
#                 options={"device": "cpu"},
#                 keep_alive="0s"
#             )["embedding"],
#             limit=10,
#             score_threshold=0,
#             query_filter=models.Filter(
#                 must=condition
#             ),
#         )
    
#     for index in range(len(result)):
#         content = f"""{result[index].payload["document"]}"""
#         search_result.append(content)
#     logging.info(f"Retrieval result: {search_result}")
#     # ti.xcom_push(key=type, value=search_result)
    
#     return search_result
